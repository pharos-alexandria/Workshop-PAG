{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dateien von TLG-E laden\n",
    "\n",
    "> Voraussetzung: CLTK funktioniert maximal mit Python 3.9\n",
    "\n",
    "Briefe von Basilius von Caesarea, Gregor von Nazianz, Gregor von Nyssa, Libanius, Synesius, Julian und Theodoret von Kyrrhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, unicodedata\n",
    "from cltk.data.fetch import FetchCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stockhausen/miniconda3/envs/workshop-pag/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import TLG as corpus\n",
    "corpus_downloader = FetchCorpus(language=\"grc\")\n",
    "corpus_downloader.import_corpus('tlg', '/mnt/c/Users/a_v_s/tlg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertierung in Unicode\n",
    "# Der Ordner \"grc/works\" muss bereits vorhanden sein\n",
    "from cltk.corpora.grc.tlg.tlgu import TLGU\n",
    "# files to be converted: \n",
    "# Basilius = 2040 – Briefe 004, \n",
    "# Gregor von Nazianz = 2022 - Briefe 001, \n",
    "# Gregor von Nyssa = 2017 – Briefe 033, \n",
    "# Theodoret = 4089 – Briefe 005, 006, 007, \n",
    "# Libanius = 2200 – Briefe 001, \n",
    "# Synesius = 2006 – Briefe 001, \n",
    "# Julian = 2003 – Briefe 013\n",
    "filesA = [\"2040\",\"2022\",\"2017\",\"2200\"]\n",
    "filesB = [\"4089\",\"2006\",\"2003\"]\n",
    "t = TLGU()\n",
    "for file in filesA:\n",
    "    t.convert(\"~/cltk_data/originals/tlg/tlg\"+file+\".txt\", \"~/cltk_data/grc/works/tlg\"+file, divide_works=True, extra_args=['X'])\n",
    "# Thdt, Synesius, Julian: anderes Nummerierungsschema \n",
    "for file in filesB:\n",
    "    t.convert(\"~/cltk_data/originals/tlg/tlg\"+file+\".txt\", \"~/cltk_data/grc/works/tlg\"+file, divide_works=True, extra_args=['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bereinigung der Dateien\n",
    "# Hyphenation und Sonderzeichen (—,(),<>,〈〉,[],†) löschen, Apostroph korrigieren\n",
    "# Normalisierung nach Unicode NFC\n",
    "# Ordner \"works-clean\" muss bereits vorhanden sein\n",
    "\n",
    "def remove_sonderzeichen(inputText):\n",
    "    inputText = re.sub(r'[()<>〈〉\\[\\]†]+', r'', inputText) \n",
    "    inputText = re.sub(r'—', r' ', inputText) \n",
    "    return re.sub(r'\\s{2,}',r' ',inputText) # remove multiple space\n",
    "def correct_apostrophe(inputText):\n",
    "    # correct apostroph = U+2019, nicht U+0027\n",
    "    return re.sub(r\"'\",r\"’\", inputText)\n",
    "def reflow(infile, outfile):\n",
    "    # from https://stackoverflow.com/a/71025588\n",
    "    with open(infile) as source, open(outfile, \"w\") as dest:\n",
    "        holdover = \"\"\n",
    "        for line in source.readlines():\n",
    "            line = correct_apostrophe(remove_sonderzeichen(unicodedata.normalize(\"NFC\", line)))\n",
    "            line = line.rstrip(\"\\n\")\n",
    "            line = line.rstrip(\" \")\n",
    "            if line.endswith(\"-\"):\n",
    "                lin, _, e = line.rpartition(\" \")\n",
    "            else:\n",
    "                lin, e = line, \"\"\n",
    "            dest.write(f\"{holdover}{lin} \\n\")\n",
    "            holdover = e[:-1]\n",
    "\n",
    "files = [\"tlg2040-004\",\"tlg2022-001\",\"tlg2017-033\",\"tlg4089-005\",\"tlg4089-006\",\"tlg4089-007\", \"tlg2200-001\", \"tlg2006-001\", \"tlg2003-013\"]\n",
    "\n",
    "for file in files:\n",
    "    reflow(os.path.expanduser(\"~/cltk_data/grc/works/\"+file+\".txt\"),os.path.expanduser(\"~/cltk_data/grc/works-clean/\"+file+\".txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auszug der einzelnen Briefe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_letters(infile, outfolder):\n",
    "    if not outfolder:\n",
    "        os.makedirs(outfolder)\n",
    "    with open(infile) as source:\n",
    "        contents = source.read()\n",
    "    letters = re.split(r\"\\n(?=\\d+)\", contents)[1:]\n",
    "    fileprefix = \"\".join(infile.split(\"/\")[-1:]).split(\".txt\")[0]\n",
    "    os.chdir(outfolder)\n",
    "    for letter in letters:\n",
    "        counter = int(re.search(\"\\d+\", letter).group())\n",
    "        thiscounter = f\"{counter:04d}\"\n",
    "        with open(fileprefix+\"_ep\"+thiscounter+\".txt\", \"w\") as dest:\n",
    "            dest.write(letter)\n",
    "    print(infile,counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2040-004.txt 366\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2022-001.txt 249\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2017-033.txt 5\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg4089-005.txt 52\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg4089-006.txt 95\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg4089-007.txt 147\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2200-001.txt 1544\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2006-001.txt 159\n",
      "/home/stockhausen/cltk_data/grc/works-clean/tlg2003-013.txt 157\n"
     ]
    }
   ],
   "source": [
    "files = [\"tlg2040-004\",\"tlg2022-001\",\"tlg2017-033\",\"tlg4089-005\",\"tlg4089-006\",\"tlg4089-007\", \"tlg2200-001\", \"tlg2006-001\", \"tlg2003-013\"]\n",
    "\n",
    "for file in files:\n",
    "    split_into_letters(os.path.expanduser(\"~/cltk_data/grc/works-clean/\"+file+\".txt\"),os.path.expanduser(\"~/cltk_data/grc/letters\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letters_statistics(infile):\n",
    "    with open(infile) as source:\n",
    "        contents = source.read()\n",
    "    letters = re.split(r\"\\n(?=\\d+)\", contents)[1:]\n",
    "    author = \"\".join(infile.split(\"/\")[-1:]).split(\".txt\")[0]\n",
    "    letter_stat = []\n",
    "    for letter in letters:\n",
    "        statistics = {}\n",
    "        counter = int(re.search(\"\\d+\", letter).group())\n",
    "        thiscounter = f\"{counter:04d}\"\n",
    "        try:\n",
    "            adressee = re.search(\"\\{([\\s\\S\\n]+?)\\}\", letter).group(1)\n",
    "        except AttributeError:\n",
    "            # if no adressee mentioned\n",
    "            adressee = \"\"\n",
    "        length = len(re.findall(\"[^\\S+?]\", letter)) # words = non-whitespace\n",
    "        statistics[\"author\"] = author\n",
    "        statistics[\"no\"] = thiscounter\n",
    "        statistics[\"adressee\"] = adressee\n",
    "        statistics[\"words\"] = length\n",
    "        letter_stat.append(statistics)\n",
    "    return letter_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "files = [\"tlg2040-004\",\"tlg2022-001\",\"tlg2017-033\",\"tlg4089-005\",\"tlg4089-006\",\"tlg4089-007\", \"tlg2200-001\", \"tlg2006-001\", \"tlg2003-013\"]\n",
    "\n",
    "statistics = []\n",
    "for file in files:\n",
    "    stat = letters_statistics(os.path.expanduser(\"~/cltk_data/grc/works-clean/\"+file+\".txt\"))\n",
    "    statistics.extend(stat)\n",
    "\n",
    "with open(os.path.expanduser(\"~/Workshop-PAG/statistics/letters_statistics.csv\"), \"w\") as statfile:\n",
    "    writer = csv.DictWriter(statfile, fieldnames=['author', 'no', 'adressee', 'words'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
